{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On s'assure qu'on utilise bien la version 2.0 de tensorflow : \n",
    "assert hasattr(tf, \"function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fashio MNIST\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(images, targets), (images_test, targets_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Get only a subpart of the dataset\n",
    "images = images[:10000]\n",
    "targets = targets [:10000]\n",
    "\n",
    "# Reshape the dataset and convert to float\n",
    "images = images.reshape(-1, 784)\n",
    "images = images.astype(float)\n",
    "images_test = images_test.reshape(-1, 784)\n",
    "images_test = images_test.astype(float)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "images = scaler.fit_transform(images)\n",
    "images_test = scaler.transform(images_test)\n",
    "\n",
    "print(images.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \n",
    "                 \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "#On affiche un exemple d'image\n",
    "plt.imshow(np.reshape(images[9], (28, 28)), cmap=\"binary\")\n",
    "plt.title(targets_names[targets[9]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line of the image -0.0142697062475628\n",
      "Associated target 5\n"
     ]
    }
   ],
   "source": [
    "print(\"First line of the image\", images[9][0])\n",
    "print(\"Associated target\", targets[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image (1, 784)\n",
      "Shape of the image (1, 784)\n"
     ]
    }
   ],
   "source": [
    "#On va d'abord transformer l'image en un vecteur de 28*28 valeurs : \n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "print(\"Shape of the image\", images[0:1].shape)\n",
    "model_output = model.predict(images[0:1])\n",
    "print(\"Shape of the image\", model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1311033  0.16113265 0.3030888  0.06470967 0.09243726 0.0396831\n",
      "  0.07304034 0.10201249 0.01154662 0.02124572]] [9]\n"
     ]
    }
   ],
   "source": [
    "#On ajoute les layers : \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation = \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "model_output = model.predict(images[0:1])\n",
    "print(model_output, targets[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Résumé du modèle : \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "loss = \"sparse_categorical_crossentropy\",\n",
    "optimizer = \"sgd\",\n",
    "metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 92us/sample - loss: 0.8031 - accuracy: 0.7271\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.4938 - accuracy: 0.8255\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.4230 - accuracy: 0.8513\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.3803 - accuracy: 0.8658\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.3508 - accuracy: 0.8783\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.3255 - accuracy: 0.8868\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.3045 - accuracy: 0.8958\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2874 - accuracy: 0.9021\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.2693 - accuracy: 0.9086\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.2543 - accuracy: 0.9146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(images, targets, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
